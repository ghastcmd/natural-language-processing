{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolução da lista 3 de NLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alunos:\n",
    "  - Eduardo Brasil Araujo\n",
    "  - Gideão Pinheiro\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers as ppb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized because the shapes did not match:\n",
      "- distilbert.embeddings.position_embeddings.weight: found shape torch.Size([512, 768]) in the checkpoint and torch.Size([8192, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "distil_config = ppb.DistilBertConfig(\n",
    "    max_position_embeddings=1024 * 8\n",
    ")\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights, config=distil_config, ignore_mismatched_sizes=True)\n",
    "model = model_class.from_pretrained(pretrained_weights, config=distil_config, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/preprocessed_website_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.cleaned_website_text\n",
    "data = data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(124)\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = data[:12]\n",
    "batch_1 = pd.DataFrame(batch_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1824 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized = batch_1[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [101, 4596, 18064, 19413, 5332, 7216, 2833, 28...\n",
      "1     [101, 2057, 22499, 2213, 3229, 2953, 3795, 205...\n",
      "2     [101, 21025, 2213, 2033, 3972, 28775, 2833, 21...\n",
      "3     [101, 3419, 6738, 9982, 3063, 3419, 6738, 4012...\n",
      "4     [101, 3296, 9353, 2213, 25583, 17899, 5860, 13...\n",
      "5     [101, 11834, 2282, 11834, 2208, 22128, 11834, ...\n",
      "6     [101, 8694, 2378, 2489, 4274, 2557, 2444, 2739...\n",
      "7     [101, 18072, 5003, 4168, 5239, 5003, 4168, 938...\n",
      "8     [101, 5460, 2444, 2678, 2006, 4115, 6819, 2624...\n",
      "9     [101, 2535, 2377, 1054, 2361, 11834, 9954, 253...\n",
      "10    [101, 6745, 4368, 2739, 4533, 2739, 2444, 2998...\n",
      "11    [101, 2522, 28748, 4372, 24269, 2522, 28748, 4...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 4800)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  101  4596 18064 ...     0     0     0]\n",
      " [  101  2057 22499 ...     0     0     0]\n",
      " [  101 21025  2213 ...     0     0     0]\n",
      " ...\n",
      " [  101  2535  2377 ...     0     0     0]\n",
      " [  101  6745  4368 ...  2121  2615   102]\n",
      " [  101  2522 28748 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\list-4\\code.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X65sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdelete(counts, exclude_index)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X65sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(arr)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X65sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m new_padded \u001b[39m=\u001b[39m remove_elements_to_match_count(padded, \u001b[39m512\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X65sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# new_padded = remove_elements_to_match_count(np.array(normal), 2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X65sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(new_padded)\n",
      "\u001b[1;32me:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\list-4\\code.ipynb Cell 17\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X65sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m max_size_array \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(line) \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m arr)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X65sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwhile\u001b[39;00m max_size_array \u001b[39m>\u001b[39m n:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X65sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     element_to_remove \u001b[39m=\u001b[39m unique_elements[np\u001b[39m.\u001b[39;49margmin(counts)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X65sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, line \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(arr):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X65sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         indices_to_remove \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(np\u001b[39m.\u001b[39marray(line) \u001b[39m==\u001b[39m element_to_remove)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32me:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1338\u001b[0m, in \u001b[0;36margmin\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1251\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m \u001b[39mReturns the indices of the minimum values along an axis.\u001b[39;00m\n\u001b[0;32m   1253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m-> 1338\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39m\u001b[39margmin\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32me:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "def remove_elements_to_match_count(arr, n):\n",
    "    arr = arr.tolist()\n",
    "    \n",
    "    unique_elements, counts = np.unique(arr, return_counts=True)\n",
    "    max_size_array = max(len(line) for line in arr)\n",
    "    \n",
    "    \n",
    "    while max_size_array > n:\n",
    "        element_to_remove = unique_elements[np.argmin(counts)]\n",
    "        \n",
    "        for i, line in enumerate(arr):\n",
    "            indices_to_remove = np.where(np.array(line) == element_to_remove)\n",
    "            arr[i] = np.delete(arr[i], indices_to_remove).tolist()\n",
    "\n",
    "        max_size_array = max(len(line) for line in arr)\n",
    "        for i, line in enumerate(arr):\n",
    "            line_length = len(line)\n",
    "            if line_length < max_size_array:\n",
    "                arr[i] += [0] * (max_size_array - line_length)\n",
    "\n",
    "        unique_elements, counts = np.unique(arr, return_counts=True)\n",
    "        \n",
    "        exclude_index = np.argmin(unique_elements)\n",
    "        \n",
    "        unique_elements = np.delete(unique_elements, exclude_index)\n",
    "        counts = np.delete(counts, exclude_index)\n",
    "        \n",
    "    \n",
    "    return np.array(arr)\n",
    "\n",
    "new_padded = remove_elements_to_match_count(padded, 512)\n",
    "# new_padded = remove_elements_to_match_count(np.array(normal), 2)\n",
    "print(new_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\list-4\\code.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X43sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m padded_shape \u001b[39m=\u001b[39m padded\u001b[39m.\u001b[39mshape\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X43sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(padded\u001b[39m.\u001b[39mflatten())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X43sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m padded[np\u001b[39m.\u001b[39misin(padded\u001b[39m.\u001b[39mflatten(), get_cut_value(padded, counts, \u001b[39m512\u001b[39;49m))\u001b[39m.\u001b[39mreshape(padded_shape)] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32me:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\list-4\\code.ipynb Cell 17\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m new_mat:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     new_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(value)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     new_value \u001b[39m=\u001b[39m new_arr[np\u001b[39m.\u001b[39misin(new_arr, np\u001b[39m.\u001b[39;49mwhere(counted_freq \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m i)[\u001b[39m0\u001b[39m])]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(new_value) \u001b[39m>\u001b[39m up_to_max:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         up_to_max \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(new_value)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32me:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\venv\\lib\\site-packages\\numpy\\core\\multiarray.py:345\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(condition, x, y)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[39m    inner(a, b, /)\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \n\u001b[0;32m    341\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m     \u001b[39mreturn\u001b[39;00m (a, b)\n\u001b[1;32m--> 345\u001b[0m \u001b[39m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[39m.\u001b[39mwhere)\n\u001b[0;32m    346\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwhere\u001b[39m(condition, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    347\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[39m    where(condition, [x, y], /)\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39m           [ 0,  3, -1]])\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m (condition, x, y)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_cut_value(orig, counted_freq, threshold):\n",
    "    new_mat = orig.tolist()\n",
    "    min_value = min(counted_freq)\n",
    "    max_value = max(counted_freq)\n",
    "    for i in range(min_value, max_value):\n",
    "        up_to_max = 0\n",
    "        for value in new_mat:\n",
    "            new_arr = np.array(value)\n",
    "            new_value = new_arr[np.isin(new_arr, np.where(counted_freq >= i)[0])]\n",
    "            if len(new_value) > up_to_max:\n",
    "                up_to_max = len(new_value)\n",
    "        \n",
    "        if up_to_max <= threshold:\n",
    "            return counted_freq[counted_freq > i]\n",
    "\n",
    "padded_shape = padded.shape\n",
    "counts = np.bincount(padded.flatten())\n",
    "padded[np.isin(padded.flatten(), get_cut_value(padded, counts, 512)).reshape(padded_shape)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_padded = padded.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 12166\n",
      "951\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (951,) (0,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\list-4\\code.ipynb Cell 19\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X46sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m to_replace \u001b[39m=\u001b[39m to_replace[to_replace \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X46sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(to_replace))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-4/code.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m new_mat\u001b[39m.\u001b[39mappend(to_replace \u001b[39m+\u001b[39;49m [\u001b[39m0\u001b[39;49m] \u001b[39m*\u001b[39;49m (\u001b[39m512\u001b[39;49m \u001b[39m-\u001b[39;49m \u001b[39mlen\u001b[39;49m(to_replace)))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (951,) (0,) "
     ]
    }
   ],
   "source": [
    "to_padd = 512 - (len(new_padded[0]) % 512)\n",
    "new_mat = []\n",
    "print(to_padd, len(new_padded[0]))\n",
    "for i, line in enumerate(new_padded):\n",
    "    to_replace = np.array(line)\n",
    "    to_replace = to_replace[to_replace != 0]\n",
    "    print(len(to_replace))\n",
    "    new_mat.append(to_replace + [0] * (512 - len(to_replace)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array(new_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 4800)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo está a criação do prompt utilizando o chat-GPT na versão 3.5\n",
    "A criação do prompt segue o que foi indicado [neste artigo](https://arxiv.org/abs/2304.10428)\n",
    "Na primeira etapa utilizamos a frase \"I am an excelent linguist\" para que as respostas sejam dadas utilizando os conhecimentos de linguística. \n",
    "Ainda nesta etapa informamos qual a tarefa queremos que seja realizada e informamos que as entidades são do tipo \"animal\" e após isso indicamos onde estão os exemplos.\n",
    "\n",
    "Na segunda etapa damos alguns exemplos, fornecendo inputs parecidos com os que ele receberia e outputs que mostram o padrão da resposta.\n",
    "\n",
    "Após isso, pedimos para que ele complete os outputs e passamos 5 inputs para que ele identifique as categorias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GPT-NER](../assets/2023-10-08_11-25.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado é mostrado abaixo:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Resultado](../assets/2023-10-08_11-25_1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
