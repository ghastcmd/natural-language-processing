{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolução da lista 3 de NLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alunos:\n",
    "  - Eduardo Brasil Araujo\n",
    "  - Gideão Pinheiro\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers as ppb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized because the shapes did not match:\n",
      "- distilbert.embeddings.position_embeddings.weight: found shape torch.Size([512, 768]) in the checkpoint and torch.Size([10240, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "distil_config = ppb.DistilBertConfig(\n",
    "    max_position_embeddings=1024 * 10,\n",
    ")\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights, config=distil_config, ignore_mismatched_sizes=True)\n",
    "model = model_class.from_pretrained(pretrained_weights, config=distil_config, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/preprocessed_website_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['cleaned_website_text', 'Category']]\n",
    "data = data[data.Category.isin(['Games', 'Food'])]\n",
    "data = data.sample(frac=1, random_state=101).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = data.rename(columns={'cleaned_website_text': 0, 'Category': 1})[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = batch_1[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded, device=torch.device('cuda'))\n",
    "attention_mask = torch.tensor(attention_mask, device=torch.device('cuda'))\n",
    "\n",
    "model.to(torch.device('cuda'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].to(torch.device('cpu')).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = batch_1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision_1 = precision_score(y_test, y_pred, pos_label='Games')\n",
    "    recall_1 = recall_score(y_test, y_pred, pos_label='Games')\n",
    "    f1_1 = f1_score(y_test, y_pred, pos_label='Games')\n",
    "    precision_2 = precision_score(y_test, y_pred, pos_label='Food')\n",
    "    recall_2 = recall_score(y_test, y_pred, pos_label='Food')\n",
    "    f1_2 = f1_score(y_test, y_pred, pos_label='Food')\n",
    "    return confusion, accuracy, precision_1, recall_1, f1_1, precision_2, recall_2, f1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(y_test, y_pred):\n",
    "    conf, acc, prec_1, recl_1, f1_1, prec_2, recl_2, f1_2 = get_all(y_test, y_pred)\n",
    "    print('Confusion:\\n', conf)\n",
    "    print('Accuracy: ', acc)\n",
    "    print('Precision (Games): ', prec_1)\n",
    "    print('Recall (Games): ', recl_1)\n",
    "    print('F1 (Games): ', f1_1)\n",
    "    print('Precision (Food): ', prec_2)\n",
    "    print('Recall (Food): ', recl_2)\n",
    "    print('F1 (Food): ', f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, train_size=0.7, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=101).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion:\n",
      " [[2 0]\n",
      " [4 0]]\n",
      "Accuracy:  0.3333333333333333\n",
      "Precision (Games):  0.0\n",
      "Recall (Games):  0.0\n",
      "F1 (Games):  0.0\n",
      "Precision (Food):  0.3333333333333333\n",
      "Recall (Food):  1.0\n",
      "F1 (Food):  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_values(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion:\n",
      " [[2 0]\n",
      " [2 2]]\n",
      "Accuracy:  0.6666666666666666\n",
      "Precision (Games):  1.0\n",
      "Recall (Games):  0.5\n",
      "F1 (Games):  0.6666666666666666\n",
      "Precision (Food):  0.5\n",
      "Recall (Food):  1.0\n",
      "F1 (Food):  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "get_values(y_test, gnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion:\n",
      " [[2 0]\n",
      " [4 0]]\n",
      "Accuracy:  0.3333333333333333\n",
      "Precision (Games):  0.0\n",
      "Recall (Games):  0.0\n",
      "F1 (Games):  0.0\n",
      "Precision (Food):  0.3333333333333333\n",
      "Recall (Food):  1.0\n",
      "F1 (Food):  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_values(y_test, svc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos resultados\n",
    "\n",
    "Os resultados da matriz de confusão apresentaram-se idênticos no modelo de\n",
    "regressão logística e SVM, com isso as demais métricas foram as mesmas, mas\n",
    "o que apresentou melhores resultados foi o de Naive-Bayes, com acurácia maior\n",
    "que o mínimo aceitável de 50%. O desenvolvimento desta questão se provou\n",
    "desafiador, uma vez que para treinar o modelo requereu uma quantidade\n",
    "de memória muito alta; e essa dificuldade se mostrou nos resultados. Provavelmente\n",
    "uma melhor otimização ou entendimento do modelo poderia melhorar os resultados.\n",
    "\n",
    "O arranjo com o Naive-Bayes apresenta-se interessante para uma situação em que\n",
    "é necessário saber com certeza se o texto dado é de fato um texto sobre games,\n",
    "uma vez que apresentou uma precisão de 100%. Os outros modelos são péssimos em tudo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo está a criação do prompt utilizando o chat-GPT na versão 3.5\n",
    "A criação do prompt segue o que foi indicado [neste artigo](https://arxiv.org/abs/2304.10428)\n",
    "Na primeira etapa utilizamos a frase \"I am an excelent linguist\" para que as respostas sejam dadas utilizando os conhecimentos de linguística. \n",
    "Ainda nesta etapa informamos qual a tarefa queremos que seja realizada e informamos que as entidades são do tipo \"animal\" e após isso indicamos onde estão os exemplos.\n",
    "\n",
    "Na segunda etapa damos alguns exemplos, fornecendo inputs parecidos com os que ele receberia e outputs que mostram o padrão da resposta.\n",
    "\n",
    "Após isso, pedimos para que ele complete os outputs e passamos 5 inputs para que ele identifique as categorias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GPT-NER](../assets/2023-10-08_11-25.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado é mostrado abaixo:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Resultado](../assets/2023-10-08_11-25_1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
