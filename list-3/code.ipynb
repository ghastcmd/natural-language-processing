{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolução da lista 3 de NLP\n",
    "## Alunos:\n",
    "    - Eduardo Brasil Araujo\n",
    "    - Gideão Pinheiro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data = pd.read_csv('../datasets/preprocessed_website_classification.csv')\n",
    "lstm_raw_data = lstm_data.cleaned_website_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 6686147\n"
     ]
    }
   ],
   "source": [
    "corpus = ''\n",
    "for data in lstm_raw_data:\n",
    "    corpus += f'{data} '\n",
    "\n",
    "print('Corpus length:', len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(corpus)))\n",
    "print('Total chars:', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 835768\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "next_chars = []\n",
    "Q = 10\n",
    "for i in range(0, len(corpus) - Q, 8):\n",
    "    sentences.append([char_indices[char] for char in corpus[i : i + Q]])\n",
    "    next_chars.append(char_indices[corpus[i + Q]])\n",
    "\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), Q, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char] = 1\n",
    "    y[i, next_chars[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\localhost\\AppData\\Local\\Temp\\ipykernel_18028\\1269519880.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=torch.float32, device=torch.device('cuda'))\n",
      "C:\\Users\\localhost\\AppData\\Local\\Temp\\ipykernel_18028\\1269519880.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32, device=torch.device('cuda'))\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(x, dtype=torch.float32, device=torch.device('cuda'))\n",
    "y = torch.tensor(y, dtype=torch.float32, device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([835768, 10, 27])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTextGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMTextGenerator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden_state):\n",
    "        output, hidden_state = self.lstm(input_seq, hidden_state)\n",
    "        output = self.fc(output.view(input_seq.size(0), -1))\n",
    "        return output, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "num_chars = len(chars)\n",
    "print(num_chars)\n",
    "input_size = num_chars\n",
    "hidden_size = 128\n",
    "output_size = num_chars\n",
    "learning_rate = 0.01\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTextGenerator(input_size, hidden_size, output_size)\n",
    "model.to(torch.device('cuda'))\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1]' is invalid for input of size 27",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32me:\\localhost\\Desktop\\dor-repos\\computer-science\\natural-language-processing\\repo\\list-3\\code.ipynb Cell 17\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-3/code.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# seq = seq.view(Q, -1)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-3/code.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m output, hidden_state \u001b[39m=\u001b[39m model(seq, hidden_state)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-3/code.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39;49mview(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-3/code.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m criterion(output, target)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/localhost/Desktop/dor-repos/computer-science/natural-language-processing/repo/list-3/code.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEnded thing\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1]' is invalid for input of size 27"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    hidden_state = None\n",
    "    loss = 0\n",
    "    for seq, target in zip(x, y):\n",
    "        optimizer.zero_grad()\n",
    "        # seq = seq.view(Q, -1)\n",
    "        output, hidden_state = model(seq, hidden_state)\n",
    "        target = target.view(1)\n",
    "        loss += criterion(output, target)\n",
    "        print('Ended thing')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # if (epoch + 1) % 1 == 0:\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Treinamento concluído!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
