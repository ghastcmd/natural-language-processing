{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolução da lista 2 de NLP\n",
    "## Alunos:\n",
    "    - Eduardo Brasil Araujo\n",
    "    - Gideão Pinheiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/website_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.cleaned_website_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1,1),\n",
    "                                   stop_words='english',\n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_features=1000)\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "np.random.shuffle(np.array(X_train))\n",
    "\n",
    "X = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "Best model's Params: {'n_components': 5}\n",
      "Best log likelihood score: -889269.6344358076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search_params = {\n",
    "  'n_components': list(range(1, 11)),\n",
    "}\n",
    "\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "grid_search = GridSearchCV(lda,\n",
    "                           param_grid=search_params,\n",
    "                           n_jobs=4,\n",
    "                           verbose=1,\n",
    "                           cv=4)\n",
    "grid_search.fit(X)\n",
    "\n",
    "print(f'Best model\\'s Params: {grid_search.best_params_}')\n",
    "print(f'Best log likelihood score: {grid_search.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respondendo item (a) da 2ª questão:\n",
    "\n",
    "- Referência: https://investigate.ai/text-analysis/choosing-the-right-number-of-topics-for-a-scikit-learn-topic-model/\n",
    "\n",
    "É notório que o modelo LDA é melhor para realizar a avaliação de quantos\n",
    "tópicos utilizar, pois ele proporciona uma métrica de avaliação bem definida,\n",
    "diferentemente de outros modelos como NMF (pelo menos no scikit-learn).\n",
    "\n",
    "Assim, foi utilizado este modelo para avaliar a quantidade de tópicos, e\n",
    "então, foi feito uma busca em grade pela combinação de parâmetros mais bem\n",
    "adaptados ao problema; com o GridSearchCV. \n",
    "\n",
    "O melhor resultado foi com o número de componentes (número de tópicos)\n",
    "igual a 5. Porém, como pode ser observado no item b desta mesma questão,\n",
    "na tabela mostrada abaixo dos tópicos foram observadas alguma anomalias.\n",
    "A tabela em questão é uma distribuição dos documentos em relação aos\n",
    "tópicos gerados, ou seja, o número representa a incidência dos tópicos em\n",
    "relação à base. A primeira anomalia observada é em SVD, com os valores\n",
    "sendo negativos. A segunda anomalia observada é o NMF com uma coluna com\n",
    "todos os valores zerados. As anomalias observadas são facilmente\n",
    "resolvidas diminuindo a quantidade de tópicos para 4, que, logo, será a\n",
    "quantidade final de tópicos escolhidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value\n",
    "number_of_components = 4\n",
    "\n",
    "# LDA\n",
    "lda = LatentDirichletAllocation(n_components=number_of_components)\n",
    "lda_topics = lda.fit_transform(X)\n",
    "\n",
    "# SVD\n",
    "svd = TruncatedSVD(n_components=number_of_components)\n",
    "svd_topics = svd.fit_transform(X)\n",
    "\n",
    "# NMF\n",
    "nmf = NMF(n_components=number_of_components)\n",
    "nmf_topics = nmf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_list(model, feature_names, n_words):\n",
    "    topic_list = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_n = ['_'.join(feature_names[i].split())\n",
    "                for i in topic.argsort()\n",
    "                [-n_words:]][::-1]\n",
    "        top_features = ' '.join(top_n)\n",
    "        topic_list.append(f\"topic_{'_'.join(top_n[:3])}\") \n",
    "\n",
    "        print(f\"Topic {topic_idx}: {top_features}\")\n",
    "    return topic_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respostas ao item (b) da 2ª questão:\n",
    "\n",
    "- Referência: https://www.freecodecamp.org/news/advanced-topic-modeling-how-to-use-svd-nmf-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: news december world new league\n",
      "Topic 1: information use new service work\n",
      "Topic 2: chat tv free sex movie\n",
      "Topic 3: recipe new add gift view\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_news_december_world</th>\n",
       "      <th>topic_information_use_new</th>\n",
       "      <th>topic_chat_tv_free</th>\n",
       "      <th>topic_recipe_new_add</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066607</td>\n",
       "      <td>18.213757</td>\n",
       "      <td>0.065194</td>\n",
       "      <td>81.654443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061580</td>\n",
       "      <td>17.872623</td>\n",
       "      <td>28.812409</td>\n",
       "      <td>53.253388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.138746</td>\n",
       "      <td>35.743256</td>\n",
       "      <td>0.143735</td>\n",
       "      <td>63.974262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.535152</td>\n",
       "      <td>0.032640</td>\n",
       "      <td>0.031903</td>\n",
       "      <td>99.400305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068734</td>\n",
       "      <td>33.046922</td>\n",
       "      <td>26.194239</td>\n",
       "      <td>40.690105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_news_december_world  topic_information_use_new  topic_chat_tv_free  \\\n",
       "0                   0.066607                  18.213757            0.065194   \n",
       "1                   0.061580                  17.872623           28.812409   \n",
       "2                   0.138746                  35.743256            0.143735   \n",
       "3                   0.535152                   0.032640            0.031903   \n",
       "4                   0.068734                  33.046922           26.194239   \n",
       "\n",
       "   topic_recipe_new_add  \n",
       "0             81.654443  \n",
       "1             53.253388  \n",
       "2             63.974262  \n",
       "3             99.400305  \n",
       "4             40.690105  "
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA\n",
    "top_feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "topic_list = get_topic_list(lda, top_feature_names, 5)\n",
    "\n",
    "amounts = lda.transform(X) * 100\n",
    "topics = pd.DataFrame(amounts, columns=topic_list)\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: news late trend new world\n",
      "Topic 1: sex phone add cart free\n",
      "Topic 2: add cart quality good fresh\n",
      "Topic 3: tv movie series comedy tvma\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_news_late_trend</th>\n",
       "      <th>topic_sex_phone_add</th>\n",
       "      <th>topic_add_cart_quality</th>\n",
       "      <th>topic_tv_movie_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421.204588</td>\n",
       "      <td>470.426578</td>\n",
       "      <td>321.653989</td>\n",
       "      <td>732.434358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>565.180837</td>\n",
       "      <td>716.901669</td>\n",
       "      <td>293.254237</td>\n",
       "      <td>980.098028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253.582559</td>\n",
       "      <td>315.719082</td>\n",
       "      <td>222.888538</td>\n",
       "      <td>424.663615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005.060191</td>\n",
       "      <td>1106.810230</td>\n",
       "      <td>732.593426</td>\n",
       "      <td>1520.173618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>469.457457</td>\n",
       "      <td>554.920273</td>\n",
       "      <td>375.323692</td>\n",
       "      <td>809.873944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_news_late_trend  topic_sex_phone_add  topic_add_cart_quality  \\\n",
       "0             421.204588           470.426578              321.653989   \n",
       "1             565.180837           716.901669              293.254237   \n",
       "2             253.582559           315.719082              222.888538   \n",
       "3            1005.060191          1106.810230              732.593426   \n",
       "4             469.457457           554.920273              375.323692   \n",
       "\n",
       "   topic_tv_movie_series  \n",
       "0             732.434358  \n",
       "1             980.098028  \n",
       "2             424.663615  \n",
       "3            1520.173618  \n",
       "4             809.873944  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD\n",
    "topic_list = get_topic_list(svd, top_feature_names, 5)\n",
    "\n",
    "amounts = svd.transform(X) * 100\n",
    "topics = pd.DataFrame(amounts, columns=topic_list)\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: news late trend india new\n",
      "Topic 1: sex phone free hot gay\n",
      "Topic 2: add cart quality fresh good\n",
      "Topic 3: tv movie series comedy tvma\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_news_late_trend</th>\n",
       "      <th>topic_sex_phone_free</th>\n",
       "      <th>topic_add_cart_quality</th>\n",
       "      <th>topic_tv_movie_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.866815</td>\n",
       "      <td>1.825468</td>\n",
       "      <td>6.045565</td>\n",
       "      <td>33.891438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.838170</td>\n",
       "      <td>6.576929</td>\n",
       "      <td>5.246591</td>\n",
       "      <td>45.258195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.626564</td>\n",
       "      <td>1.636281</td>\n",
       "      <td>5.058541</td>\n",
       "      <td>20.275164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.544271</td>\n",
       "      <td>6.026568</td>\n",
       "      <td>15.552746</td>\n",
       "      <td>72.585468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.004599</td>\n",
       "      <td>2.505878</td>\n",
       "      <td>7.496795</td>\n",
       "      <td>38.040051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_news_late_trend  topic_sex_phone_free  topic_add_cart_quality  \\\n",
       "0               2.866815              1.825468                6.045565   \n",
       "1               3.838170              6.576929                5.246591   \n",
       "2               1.626564              1.636281                5.058541   \n",
       "3               8.544271              6.026568               15.552746   \n",
       "4               3.004599              2.505878                7.496795   \n",
       "\n",
       "   topic_tv_movie_series  \n",
       "0              33.891438  \n",
       "1              45.258195  \n",
       "2              20.275164  \n",
       "3              72.585468  \n",
       "4              38.040051  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NMF\n",
    "topic_list = get_topic_list(nmf, top_feature_names, 5)\n",
    "\n",
    "amounts = nmf.transform(X) * 100\n",
    "topics = pd.DataFrame(amounts, columns=topic_list)\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resposta do item (c) da 2ª questão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing documents\n",
    "indexes = np.random.choice(range(len(data)), 5)\n",
    "choosen_documents = []\n",
    "choosen_documents_categories = []\n",
    "for index in indexes:\n",
    "    choosen_documents_categories.append(data.Category[index])\n",
    "    choosen_documents.append(data.cleaned_website_text[index])\n",
    "choosen_documents = np.array(choosen_documents)\n",
    "choosen_documents_categories = np.array(choosen_documents_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NMF(n_components=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NMF</label><div class=\"sk-toggleable__content\"><pre>NMF(n_components=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NMF(n_components=3)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_topics = 3\n",
    "\n",
    "count_vectorizer_3 = CountVectorizer(ngram_range=(1,1),\n",
    "                                   stop_words='english',\n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_features=1000)\n",
    "\n",
    "choosen_documents_converted = count_vectorizer.fit_transform(choosen_documents)\n",
    "\n",
    "# LDA\n",
    "lda_3 = LatentDirichletAllocation(n_components=num_topics)\n",
    "lda_3.fit(choosen_documents_converted)\n",
    "\n",
    "# SVD\n",
    "svd_3 = TruncatedSVD(n_components=num_topics)\n",
    "svd_3.fit(choosen_documents_converted)\n",
    "\n",
    "# NMF\n",
    "nmf_3 = NMF(n_components=num_topics)\n",
    "nmf_3.fit(choosen_documents_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics\n",
      "Topic 0: mayo clinic condition botany letter\n",
      "Topic 1: base visit videos overview blog\n",
      "Topic 2: date somaiya single site dating\n",
      "SVD Topics\n",
      "Topic 0: mayo clinic condition letter begin\n",
      "Topic 1: botany plant science somaiya life\n",
      "Topic 2: somaiya programme place student life\n",
      "NMF Topics\n",
      "Topic 0: mayo clinic condition letter begin\n",
      "Topic 1: botany plant science math tech\n",
      "Topic 2: somaiya place programme life student\n"
     ]
    }
   ],
   "source": [
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "print('LDA Topics')\n",
    "lda_topics_str = get_topic_list(lda_3, feature_names, 5)\n",
    "print('SVD Topics')\n",
    "svd_topics_str = get_topic_list(svd_3, feature_names, 5)\n",
    "print('NMF Topics')\n",
    "nmf_topics_str = get_topic_list(nmf_3, feature_names, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escrevendo documento para ler os dados\n",
    "with open('output_file.txt', 'wb') as fp:\n",
    "    for outer_index, line in enumerate(choosen_documents.tolist()):\n",
    "        fp.write(f'\\n{\"#\" * 30}\\n'.encode('utf-8'))\n",
    "        fp.write(f'\\n{choosen_documents_categories[outer_index]}\\n\\n'.encode('utf-8'))\n",
    "        for index, word in enumerate(line.split()):\n",
    "            fp.write(f'{word} '.encode('utf-8'))\n",
    "            if (index + 1) % 12 == 0:\n",
    "                fp.write('\\n'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resposta do item (d) da 2ª questão:\n",
    "\n",
    "- Referência: https://stackoverflow.com/questions/60613532/how-do-i-calculate-the-coherence-score-of-an-sklearn-lda-model#62151839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import gensim.corpora as corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Cv(model, df_columnm):\n",
    "  topics = model.components_\n",
    "\n",
    "  n_top_words = 20\n",
    "  texts = [[word for word in doc.split()] for doc in df_columnm]\n",
    "\n",
    "  # create the dictionary\n",
    "  dictionary = corpora.Dictionary(texts)\n",
    "  # Create a gensim dictionary from the word count matrix\n",
    "\n",
    "  # Create a gensim corpus from the word count matrix\n",
    "  corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "  feature_names = [dictionary[i] for i in range(len(dictionary))]\n",
    "\n",
    "  # Get the top words for each topic from the components_ attribute\n",
    "  top_words = []\n",
    "  for topic in topics:\n",
    "      top_words.append([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "\n",
    "  coherence_model = CoherenceModel(topics=top_words, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "  coherence = coherence_model.get_coherence()\n",
    "  return coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_coherence = get_Cv(lda, X_train)\n",
    "svd_coherence = get_Cv(svd, X_train)\n",
    "nmf_coherence = get_Cv(nmf, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4469203505209559\n",
      "0.4439693854804786\n",
      "0.42701229768501564\n"
     ]
    }
   ],
   "source": [
    "print(lda_coherence)\n",
    "print(svd_coherence)\n",
    "print(nmf_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_3_coherence = get_Cv(lda_3, choosen_documents)\n",
    "svd_3_coherence = get_Cv(svd_3, choosen_documents)\n",
    "nmf_3_coherence = get_Cv(nmf_3, choosen_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6971816854566728\n",
      "0.7134016171306804\n",
      "0.7126874769842947\n"
     ]
    }
   ],
   "source": [
    "print(lda_3_coherence)\n",
    "print(svd_3_coherence)\n",
    "print(nmf_3_coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justificativa\n",
    "\n",
    "É notório que os resultados dos três modelos foram similares, tanto numa análise\n",
    "manual, com a leitura de cada um deles. Como também com a métrica de coerência\n",
    "(métrica que avalia a interpretabilidade dos tópicos) apresenta-se altamente\n",
    "similar, mas que, ao mesmo tempo, percebe-se que o modelo SVD se saiu bem em\n",
    "ambos os testes (o com a base toda e outro com somente 5 documentos). Portanto,\n",
    "o SVD é escolhido como o que melhor se desempenhou, contudo os resultados são\n",
    "praticamente os mesmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
